@article{Krizhevsky2012,
abstract = {We trained a large, deep convolutional neural network to classify the 1.2 million high-resolution images in the ImageNet LSRVRC-2010 contest into the 1000 different classes. On the test data, we achieved top-1 and top-5 error rates of 37.5{\%} and 17.0{\%} which is considerably better than the previous state of the art. The neural network, which has 60 million paramters and 650,000 neurons, consists of five convolutional layers, some of which are followed by max-pooling layers, and three fully connected layers with a final 1000-way softmax. To make training faster, we used non-saturating neurons and a very efficient GPU implementation of the convolutional operation. To reduce overfitting in the fully-connected layers, we employed a recently-developed method called 'dropout' that proved to be effective. We also entered a variant of the model in the ILSVRC-2012 competition and achievd a top-5 test error rate of 15.3{\%}, compared to 26.2{\%} achieved by the second-best entry.},
archivePrefix = {arXiv},
arxivId = {1102.0183},
author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E},
doi = {http://dx.doi.org/10.1016/j.protcy.2014.09.007},
eprint = {1102.0183},
file = {:home/cholo/Desktop/up-files/ENG10/ImageNet{\_}Deep{\_}CNN-Krizhevsky.pdf:pdf},
isbn = {9781627480031},
issn = {10495258},
journal = {Advances In Neural Information Processing Systems},
pages = {1--9},
pmid = {7491034},
title = {{ImageNet Classification with Deep Convolutional Neural Networks}},
year = {2012}
}

@article{OShea2015,
abstract = {The field of machine learning has taken a dramatic twist in recent times, with the rise of the Artificial Neural Network (ANN). These biologically inspired computational models are able to far exceed the performance of previous forms of artificial intelligence in common machine learning tasks. One of the most impressive forms of ANN architecture is that of the Convolutional Neural Network (CNN). CNNs are primarily used to solve difficult image-driven pattern recognition tasks and with their precise yet simple architecture, offers a simplified method of getting started with ANNs. This document provides a brief introduction to CNNs, discussing recently published papers and newly formed techniques in developing these brilliantly fantastic image recognition models. This introduction assumes you are familiar with the fundamentals of ANNs and machine learning.},
archivePrefix = {arXiv},
arxivId = {1511.08458},
author = {O'Shea, Keiron and Nash, Ryan},
eprint = {1511.08458},
file = {:home/cholo/Desktop/up-files/ENG10/Intro{\_}To{\_}CNN-OShea.pdf:pdf},
number = {November},
title = {{An Introduction to Convolutional Neural Networks}},
url = {http://arxiv.org/abs/1511.08458},
year = {2015}
}

@article{Akmeliawati2007,
abstract = {In this paper we present an automatic visual-based sign language translation system. Our proposed automatic sign-language translator provides a real-time English translation of the Malaysia SL. To date, there have been studies on sign language recognition based on visual approach (video camera). However, the emphasis on these works is limited to a small lexicon of sign language or solely focuses on fingerspelling, which takes different approaches respectively. In practical sense, fingerspelling is used if a word cannot be expressed via sign language. Our sign language translator can recognise both fingerspelling and sign gestures that involve static and motion signs. Trained neural networks are used to identify the signs to translate into English.},
author = {Akmeliawati, Rini and Ooi, Melanie Po-Leen and Kuang, Ye Chow},
doi = {10.1109/IMTC.2007.379311},
file = {:home/cholo/Desktop/up-files/ENG10/Segmentation{\_}And{\_}NN-Akmeliawati.pdf:pdf},
isbn = {1-4244-1080-0},
issn = {1091-5281},
journal = {2007 IEEE Instrumentation {\&} Measurement Technology Conference IMTC 2007},
keywords = {-image processing,neural network,sign language},
number = {May},
pages = {1--6},
title = {{Real-Time Malaysian Sign Language Translation using Colour Segmentation and Neural Network}},
url = {http://ieeexplore.ieee.org/document/4258110/},
year = {2007}
}

@article{Chai,
author = {Chai, Xiujuan and Li, Guang and Lin, Yushun and Xu, Zhihao and Tang, Yili and Chen, Xilin},
file = {:home/cholo/Downloads/Kinect.pdf:pdf},
keywords = {-sign language,3d motion trajectory,hand tracking},
title = {{Sign Language Recognition and Translation with Kinect}}
}

@article{Szegedy2014,
archivePrefix = {arXiv},
arxivId = {arXiv:1512.00567v3},
author = {Szegedy, Christian and Vanhoucke, Vincent and Shlens, Jonathon and Wojna, Zbigniew},
eprint = {arXiv:1512.00567v3},
file = {:home/cholo/Downloads/Inception.pdf:pdf},
title = {{Rethinking the Inception Architecture for Computer Vision}},
year = {2014}
}

@article{Villamor2018,
author = {Villamor, Graceal S and Samaniego, Jaime M},
file = {:home/cholo/Desktop/up-files/ENG10/SVM-Villamor.pdf:pdf},
pages = {1--8},
title = {{A Gesture-to-Speech Assistive Application}},
year = {2018}
}

@book{Wilcox1991,
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Wilcox, Sherman and Wilcox, Phyllis Perrin},
doi = {10.1017/CBO9781107415324.004},
eprint = {arXiv:1011.1669v3},
file = {:home/cholo/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Wilcox, Wilcox - 1991 - Learning to see Teaching American Sign Language as a Second Language.pdf:pdf;:home/cholo/Desktop/up-files/ENG10/ASL{\_}As{\_}Second{\_}Language-Wilcox.pdf:pdf},
isbn = {9788578110796},
issn = {1098-6596},
pmid = {25246403},
title = {{Learning to see: Teaching American Sign Language as a Second Language}},
year = {1991}
}

@article{Sharma2015,
abstract = {Abstract: Hand gesture recognition has proven to be an excellent means of Human Computer Interaction over other approaches through keyboards and mouse. This paper presents a review of the evolution of this excellent, easy and natural way of Human Machine Interaction. In this review article the advantages and disadvantages of various techniques that have come up with time and ongoing researches in this field have been discussed. Most of the researchers initially used gloves for the interaction, and then came the vision based hand gesture recognition for 2D graphical interface which uses colour extraction through optical flow and feature point extraction of the hand image captured. New ideas and algorithms have come for 3D applications for moving machine parts or humans. This evolution has resulted in developing a low cost interface device for interacting with objects in virtual environment using hand gestures. Finally, the future work that can be done in this field is also discussed.},
author = {Sharma, Praveen Kumar and Sharma, Shreya},
file = {:home/cholo/Desktop/up-files/ENG10/EvolutionOfHandGestureScharma.pdf:pdf},
journal = {International Journal Of Engineering And Computer Science},
keywords = {gesture recognition,hand gesture,human computer interaction,image processing},
number = {1},
pages = {9962--9965},
title = {{Evolution of Hand Gesture Recognition : A Review}},
volume = {4},
year = {2015}
}

@article{Wu2016,
abstract = {The field of machine learning has taken a dramatic twist in recent times, with the rise of the Artificial Neural Network (ANN). These biologically inspired computational models are able to far exceed the performance of previous forms of artificial intelligence in common machine learning tasks. One of the most impressive forms of ANN architecture is that of the Convolutional Neural Network (CNN). CNNs are primarily used to solve difficult image-driven pattern recognition tasks and with their precise yet simple architecture, offers a simplified method of getting started with ANNs. This document provides a brief introduction to CNNs, discussing recently published papers and newly formed techniques in developing these brilliantly fantastic image recognition models. This introduction assumes you are familiar with the fundamentals of ANNs and machine learning.},
archivePrefix = {arXiv},
arxivId = {1111.6189v1},
author = {Wu, Jianxin},
doi = {10.1007/978-3-642-28661-2-5},
eprint = {1111.6189v1},
file = {:home/cholo/Desktop/up-files/ENG10/Intro{\_}To{\_}CNN-Wu.pdf:pdf},
isbn = {9783642286605},
issn = {1860949X},
pages = {1--28},
pmid = {23109523},
title = {{Introduction to Convolutional Neural Networks}},
year = {2016}
}

@article{Schmidhuber2015,
abstract = {In recent years, deep artificial neural networks (including recurrent ones) have won numerous contests in pattern recognition and machine learning. This historical survey compactly summarizes relevant work, much of it from the previous millennium. Shallow and Deep Learners are distinguished by the depth of their credit assignment paths, which are chains of possibly learnable, causal links between actions and effects. I review deep supervised learning (also recapitulating the history of backpropagation), unsupervised learning, reinforcement learning {\&} evolutionary computation, and indirect search for short programs encoding deep and large networks.},
archivePrefix = {arXiv},
arxivId = {1404.7828},
author = {Schmidhuber, J{\"{u}}rgen},
doi = {10.1016/j.neunet.2014.09.003},
eprint = {1404.7828},
file = {:home/cholo/Desktop/up-files/ENG10/DeepLearningInNeuralNetworksOverview.JSchmidhuber2015.pdf:pdf},
isbn = {0893-6080},
issn = {18792782},
journal = {Neural Networks},
keywords = {Deep learning,Evolutionary computation,Reinforcement learning,Supervised learning,Unsupervised learning},
pages = {85--117},
pmid = {25462637},
publisher = {Elsevier Ltd},
title = {{Deep Learning in neural networks: An overview}},
url = {http://dx.doi.org/10.1016/j.neunet.2014.09.003},
volume = {61},
year = {2015}
}

@electronic{WHO2018,
author = {WorldHealthOrganization},
title = {{Deafness and hearing loss}},
url = {http://www.who.int/news-room/fact-sheets/detail/deafness-and-hearing-loss},
year = {2018}
}

@IEEEtranBSTCTL{IEEEexample:BSTcontrol,
CTLuse_article_number     = "yes",
CTLuse_paper              = "yes",
CTLuse_forced_etal        = "no",
CTLmax_names_forced_etal  = "10",
CTLnames_show_etal        = "1",
CTLuse_alt_spacing        = "yes",
CTLalt_stretch_factor     = "4",
CTLdash_repeated_names    = "yes",
CTLname_format_string     = "{f.~}{vv~}{ll}{, jj}",
CTLname_latex_cmd         = ""
}
